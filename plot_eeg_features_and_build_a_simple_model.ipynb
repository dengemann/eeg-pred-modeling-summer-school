{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "import config_chbp_eeg as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some viz config\n",
    "small_size, medium_size, bigger_size = 13, 18, 18\n",
    "\n",
    "plt.rc('font', size=small_size)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=small_size)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=medium_size)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=small_size)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=small_size)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=small_size)    # legend fontsize\n",
    "plt.rc('figure', titlesize=bigger_size)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-hamilton",
   "metadata": {},
   "source": [
    "## First we read in some meta data needed for the present task\n",
    "\n",
    "1. we need the demographic information\n",
    "\n",
    "2. we need to know for which participants we have data\n",
    "\n",
    "3. we need to sync both pieces of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_demographics = pd.read_csv('./inputs/Demographic_data.csv', header=1)\n",
    "\n",
    "# remove empty columns\n",
    "df_demographics = df_demographics.iloc[:, :5].set_index('Code')\n",
    "df_demographics\n",
    "\n",
    "\n",
    "# The later code uses the prefix \"sub-\" in the participants identifier, we will add it here to be fine\n",
    "\n",
    "df_demographics.index = \"sub-\" + df_demographics.index\n",
    "df_demographics.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we read in the processing log to see for which participants we have EEG\n",
    "\n",
    "proc_log = pd.read_csv('./outputs/autoreject_log.csv')\n",
    "good_subjects = proc_log.query('ok == \"OK\"').subject\n",
    "good_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we filter the demographic list accordingly and establish the same order\n",
    "\n",
    "df_demographics = df_demographics.loc[good_subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can put some data aside for testing and focus on 80 percent of the cases for exploring\n",
    "\n",
    "train_cases, test_cases = train_test_split(df_demographics, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the age distribution to get an idea who we are dealing with here\n",
    "\n",
    "train_cases.Age.hist()\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('Age [years]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-tulsa",
   "metadata": {},
   "source": [
    "## Let's read in the pre-computed featurs\n",
    "\n",
    "We first start with the power spectra. As we read, we make sure features are stored in\n",
    "the same order as our meta info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = mne.externals.h5io.read_hdf5('./outputs/features_eyes-closed.h5')\n",
    "psds = [features[sub]['psds'] for sub in train_cases.index]\n",
    "X_psd = np.array(psds)\n",
    "print(X_psd.shape)  # hooray we have an array! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what are these dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better plotting options we may later need the channel layout\n",
    "# As we picked common channels, we need to know what are the remaining channels.\n",
    "\n",
    "ch_names = pd.read_csv('./outputs/common_channels_validated.csv').name.tolist()\n",
    "print(ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get the frequency information from the features file\n",
    "\n",
    "freqs = features[train_cases.index[0]]['meta_info']['freqs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-attempt",
   "metadata": {},
   "source": [
    "## Let's explore link between EEG power and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do something crude first: averaging over all channels and taking the log\n",
    "\n",
    "X_psd_ave = np.log10(X_psd.mean(1))\n",
    "X_psd_ave.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visually explore the link between power and age by somple plotting with color codes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y = train_cases.Age.values\n",
    "\n",
    "age_sorter = np.argsort(y)\n",
    "sorted_age = y[age_sorter]\n",
    "\n",
    "ms = MinMaxScaler()\n",
    "color_code = ms.fit_transform(sorted_age[:, None])[:, 0]\n",
    "color = plt.matplotlib.cm.viridis(color_code)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "for ii, psd in enumerate(X_psd_ave[age_sorter]):\n",
    "    plt.plot(freqs, psd, color=color[ii]);\n",
    "# plt.ylim(-16, -8)\n",
    "plt.ylabel(r'$10 \\times \\log_{10}(PSD)$')\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-burst",
   "metadata": {},
   "source": [
    "### Oh no!! We have a really bad outlier here! Lets' get rid of this one and do it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx = X_psd_ave.mean(1).argmin()\n",
    "good_idx = list(range(len(X_psd_ave)))\n",
    "good_idx.pop(bad_idx)\n",
    "\n",
    "y = train_cases.Age.values[good_idx]\n",
    "age_sorter = np.argsort(y)\n",
    "sorted_age = y[age_sorter]\n",
    "\n",
    "X_psd_ave = X_psd_ave[good_idx]\n",
    "\n",
    "ms = MinMaxScaler()\n",
    "color_code = ms.fit_transform(sorted_age[:, None])[:, 0]\n",
    "color = plt.matplotlib.cm.viridis(color_code)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "for ii, psd in enumerate(X_psd_ave[age_sorter]):\n",
    "    plt.plot(freqs, psd, color=color[ii]);\n",
    "# plt.ylim(-16, -8)\n",
    "plt.ylabel(r'$10 \\times \\log_{10}(PSD)$')\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-parking",
   "metadata": {},
   "source": [
    "This does not reveal a clear pattern yet. Let's see if binning by age group gives a clearer picture. For this we shall add a gorup variable to our data frame. After looking at the histogram above, my gut feeling is telling me that we can do around 4 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-colonial",
   "metadata": {},
   "source": [
    "Now we als have to remember to remove that bad index from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cases = train_cases.iloc[good_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cases['age_group'] = pd.cut(train_cases.Age, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can do a group by after setting the index to range\n",
    "train_cases = train_cases.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-alfred",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# note that we have now a 0-based RangeIndex that we can use to access the features\n",
    "train_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = plt.cm.viridis(np.linspace(0.1, 0.9, 4))\n",
    "plt.figure(figsize=(9, 7))\n",
    "for ii, (key, inds) in enumerate(train_cases.groupby('age_group').groups.items()):\n",
    "    plt.plot(freqs, X_psd_ave[inds].mean(0), color=color[ii], label=key, linewidth=3)\n",
    "plt.legend()\n",
    "plt.ylabel(r'$10 \\times \\log_{10}(PSD)$')\n",
    "plt.xlabel(\"Frequency [Hz]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-conflict",
   "metadata": {},
   "source": [
    "Now we can see that that oldest people have much lower alpha power, which I would expect based on my prior knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-fitness",
   "metadata": {},
   "source": [
    "## Spatial patterns\n",
    "\n",
    "Yet another way to look at things is spatial. We now use the previously defined age groups to extract EEG topographies.\n",
    "We will need MNE Python here to get this job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compose a header object to handel channel locations\n",
    "info = mne.create_info(ch_names=ch_names, ch_types=['eeg'] * len(ch_names), sfreq=200.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average EEG power for every channel across frequencies within age groups\n",
    "age_groups = train_cases.groupby('age_group').groups\n",
    "\n",
    "X_ave = np.array([X_psd[inds].mean(0).mean(1) for inds in age_groups.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ave.shape  # frequency bands, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake being an MNE Evoked object :D\n",
    "average_psds = mne.EvokedArray(data=X_ave.T, info=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to add the channel information using a standard montage\n",
    "\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "average_psds.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-survey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_psd = average_psds.plot_topomap(cmap='viridis', cbar_fmt='', vmin=np.min, vmax=np.max, show=False);\n",
    "titles = [k for k in age_groups.keys()] + [r'$10 \\times \\log_{10}(PSD)$']\n",
    "axes = fig_psd.findobj(plt.Axes)\n",
    "for ii, ax in enumerate(axes):\n",
    "    ax.set_title(titles[ii])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-encoding",
   "metadata": {},
   "source": [
    "This is unfortunately inconclive. It is possible that occular artifacts are overshadowing what we're interested in. Let's do something crude and remove the frontal channels. But how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_psds.plot_sensors(show_names=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_psds.drop_channels(['Fp1', 'Fp2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-commissioner",
   "metadata": {},
   "source": [
    "Will it be better now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_psd = average_psds.plot_topomap(cmap='viridis', cbar_fmt='', vmin=np.min, vmax=np.max, show=False);\n",
    "titles = [k for k in age_groups.keys()] + [r'$10 \\times \\log_{10}(PSD)$']\n",
    "axes = fig_psd.findobj(plt.Axes)\n",
    "for ii, ax in enumerate(axes):\n",
    "    ax.set_title(titles[ii])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-world",
   "metadata": {},
   "source": [
    "Well let's say a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_psds.drop_channels(['AF3', 'AF4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_psd = average_psds.plot_topomap(cmap='viridis', cbar_fmt='', vmin=np.min, vmax=np.max, show=False);\n",
    "titles = [k for k in age_groups.keys()] + [r'$10 \\times \\log_{10}(PSD)$']\n",
    "axes = fig_psd.findobj(plt.Axes)\n",
    "for ii, ax in enumerate(axes):\n",
    "    ax.set_title(titles[ii])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-course",
   "metadata": {},
   "source": [
    "# Additional exercise for plotting:\n",
    "\n",
    "\n",
    "\n",
    "1. Compute pearson correlations (or linear models) to capture and visulaize the link between age and power at each frequency.\n",
    "Then plot it!\n",
    "\n",
    "2. how do things look for the eyes opened condition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-conversion",
   "metadata": {},
   "source": [
    "# A first naive model\n",
    "\n",
    "Shall we still try to see if a stats model can do better than us and find patterns that predict the age?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_selection_idx = (freqs > 2) & (freqs < 20)\n",
    "\n",
    "# let's select some channel regions and average\n",
    "\n",
    "chan_selection = [ch for ch in ch_names if ch.startswith(\"P\")]\n",
    "chan_selection_idx = [info['ch_names'].index(ch) for ch in chan_selection]\n",
    "X_parietal = X_psd[:, chan_selection_idx][:, :, freq_selection_idx]\n",
    "\n",
    "chan_selection = [ch for ch in ch_names if ch.startswith(\"C\")]\n",
    "chan_selection_idx = [info['ch_names'].index(ch) for ch in chan_selection]\n",
    "X_central = X_psd[:, chan_selection_idx][:, :, freq_selection_idx]\n",
    "\n",
    "X_ = np.concatenate([X_central.mean(1), X_parietal.mean(1)], axis=1)[good_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = make_pipeline(StandardScaler(), Ridge(alpha=1))\n",
    "y_pred = cross_val_predict(estimator=ridge, X=X_, y=y)\n",
    "plt.scatter(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-owner",
   "metadata": {},
   "source": [
    "### Ugh ... negative predictions ... maybe we can use a model that does not allow for that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import GammaRegressor\n",
    "gamma = make_pipeline(StandardScaler(), GammaRegressor(alpha=1))\n",
    "y_pred_gamma = cross_val_predict(estimator=gamma, X=X_, y=y)\n",
    "plt.scatter(y, y_pred_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_true=y, y_pred=y_pred_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./outputs/demo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-hardware",
   "metadata": {},
   "source": [
    "# Additional exercise for modeling:\n",
    "\n",
    "\n",
    "1. What happens if we do not remove the bad case?\n",
    "\n",
    "2. Do these models generalize to the 50 left-out subjects?\n",
    "\n",
    "3. Can performance be improved by removing the frontal channels? and would that be a good idea? \n",
    "\n",
    "4. Can you come up with better ad-hoc features based on what we have seen?\n",
    "\n",
    "5. Can a loss that is robust to outliers help? What about changing the regularization parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-turning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python39164bitbasecondae0fabca903dd46b1afc808730ddf177a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
